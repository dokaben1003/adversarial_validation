{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a133b37f",
   "metadata": {},
   "source": [
    "### Cross Validation with Traget encording & Adversarial varidation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed7ed65",
   "metadata": {},
   "source": [
    "### 0. preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66dd524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "import lightgbm as lgb\n",
    "import optuna.integration.lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as st\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903a24a9",
   "metadata": {},
   "source": [
    "### 1. split train/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd35d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy original train/test data\n",
    "tmp_train = train.copy()\n",
    "tmp_test = test.copy()\n",
    "\n",
    "\n",
    "N_SPLITS = 3\n",
    "SEED = 408\n",
    "kf = GroupKFold(n_splits=N_SPLITS)\n",
    "generator = kf.split(tmp_train, tmp_train[\"OBJECT\"],ori_train[\"GROUP_K_FEATURE\"])\n",
    "\n",
    "x_tr_box = []\n",
    "y_tr_box = []\n",
    "x_va_box = []\n",
    "y_va_box = []\n",
    "\n",
    "\n",
    "# まず訓練データからテストデータのtarget_encording featureを作成\n",
    "for target_col in cate_col:\n",
    "    if \"OBJECT\" != target_col:\n",
    "        for stat in [\"mean\",\"std\",\"median\",\"min\",\"max\",\"var\"]:\n",
    "            target_mean = ori_train.groupby(target_col)[\"OBJECT\"].agg(stat)\n",
    "            ori_test[\"{}_target_{}\".format(target_col,stat)] = ori_test[target_col].map(target_mean).astype(\"float\")\n",
    "            \n",
    "\n",
    "# 次にtrainとvalidationデータのtarget_encording featureを作成\n",
    "for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "    \n",
    "    # 学習用と検証用に分ける\n",
    "    x_train = ori_train.iloc[idx_train].drop(\"OBJECT\", axis=1)\n",
    "    y_train = ori_train.iloc[idx_train][\"OBJECT\"]\n",
    "    x_valid = ori_train.iloc[idx_valid].drop(\"OBJECT\", axis=1)\n",
    "    y_valid = ori_train.iloc[idx_valid][\"OBJECT\"]\n",
    "    \n",
    "    \n",
    "    # target_encording\n",
    "    for target_col in cate_col:\n",
    "        # 学習データを全て使って検証用のtarget_encording columnを作成\n",
    "        if \"OBJECT\" != target_col:\n",
    "            for stat in [\"mean\",\"std\",\"median\",\"min\",\"max\",\"var\"]:\n",
    "\n",
    "                data_tmp = pd.DataFrame({\"tmp_col\" : x_train[target_col],\"OBJECT\":y_train})\n",
    "                target_mean = data_tmp.groupby(\"tmp_col\")[\"OBJECT\"].agg(stat)\n",
    "                x_valid[\"{}_target_{}\".format(target_col,stat)] = x_valid[target_col].map(target_mean).astype(\"float\")\n",
    "            \n",
    "                #学習データを分割し、out-of-foldでtarget_encording columnを作成\n",
    "                kf_encording = StratifiedKFold(n_splits=5)\n",
    "                generator = kf_encording.split(x_train, x_train[\"VAIDATION_GROUP_K_FEATURE\"])\n",
    "                tmp = np.repeat(np.nan, x_train.shape[0])\n",
    "                for fold_2, (idx_1, idx_2) in enumerate(generator):\n",
    "                    \n",
    "                    target_mean = data_tmp.iloc[idx_1].groupby(\"tmp_col\")[\"OBJECT\"].agg(stat)\n",
    "                    tmp[idx_2] = x_train[target_col].iloc[idx_2].map(target_mean)\n",
    "\n",
    "                x_train.loc[:, \"{}_target_{}\".format(target_col,stat)] = tmp\n",
    "                \n",
    "            \n",
    "    x_tr_box.append(x_train)\n",
    "    y_tr_box.append(y_train)\n",
    "    x_va_box.append(x_valid)\n",
    "    y_va_box.append(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef3ff9e",
   "metadata": {},
   "source": [
    "### 2. split train/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee330b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ar = []\n",
    "\n",
    "# 各validation_setでadversarial_varidationを行う\n",
    "for fold in range(len(x_va_box)):\n",
    "\n",
    "    # train : 0、test : 1\n",
    "    ad_data_tr = pd.concat([x_tr_box[fold],x_va_box[fold]],axis=0).drop(\"OBJECT\",axis=1)\n",
    "    ad_data_tr[\"adversatial_feature\"] = 0\n",
    "    ad_data_te = ori_test.copy()\n",
    "    ad_data_te[\"adversatial_feature\"] = 1\n",
    "    ad_data = pd.concat([ad_data_tr,ad_data_te],axis=0).sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    kf = GroupKFold(n_splits=N_SPLITS)\n",
    "    generator = kf.split(ad_data, ad_data[\"adversatial_feature\"],ad_data[\"GROUP_K_FEATURE\"])\n",
    "    \n",
    "    ad_data = ad_data.drop(com, axis=1)\n",
    "    \n",
    "    \n",
    "    for fold, (idx_train, idx_valid) in enumerate(generator):\n",
    "        # 学習用と検証用に分ける\n",
    "        x_train = ad_data.iloc[idx_train].drop([\"adversatial_feature\"], axis=1)\n",
    "        y_train = ad_data.iloc[idx_train][\"adversatial_feature\"]\n",
    "        x_valid = ad_data.iloc[idx_valid].drop([\"adversatial_feature\"], axis=1)\n",
    "        y_valid = ad_data.iloc[idx_valid][\"adversatial_feature\"]\n",
    "        \n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        lgb_valid = lgb.Dataset(x_valid, y_valid)\n",
    "        model = lgb.train(\n",
    "          params = {\n",
    "              'objective': 'regression',\n",
    "              'metric': 'rmse',\n",
    "              'learning_rate': 0.01,\n",
    "              'boosting': 'gbdt',\n",
    "              'seed': SEED,\n",
    "          },\n",
    "          train_set = lgb_train,\n",
    "          num_boost_round = 500,\n",
    "          valid_sets = [lgb_train, lgb_valid],\n",
    "          early_stopping_rounds = 10,\n",
    "          verbose_eval = 50,\n",
    "        )\n",
    "        \n",
    "        feature_ar.append(model.feature_importance())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68dccd0",
   "metadata": {},
   "source": [
    "### 3. 特徴量の重要度をランキング化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79faa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ランキングが高いほど不要な変数\n",
    "fea = pd.DataFrame()\n",
    "fea[\"col\"] = x_valid.columns\n",
    "fea[\"importance\"] = np.mean(feature_ar,axis=0)\n",
    "fea.sort_values(by=\"importance\", ascending=False).head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
